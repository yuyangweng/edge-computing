{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "logicgates_(2).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuyangweng/edge-computing/blob/main/logicgates_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBLxubN6F0Od"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Dropout\n",
        "import numpy as np\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7RqiGBrF0Oh"
      },
      "source": [
        "def logical_gate(X,Y): \n",
        "    model = models.Sequential()\n",
        "    model.add(Dense(8, activation='relu', input_shape=(2,),name='layer1'))\n",
        "    model.add(Dense(16, activation='relu',name='layer2'))\n",
        "    #model.add(Dense(1, activation='sigmoid')) # if y is 0 or 1\n",
        "    model.add(Dense(1, activation='tanh',name='layer3')) # if y is 0 or 1\n",
        "    #print(model.summary())\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy']) # binary_crossentropy\n",
        "   \n",
        "    model.fit(X, Y,epochs=200,verbose=1) \n",
        "    return model\n",
        "\n",
        "  \n",
        "def gate_predict_prob(model,X):\n",
        "    return model.predict(X)\n",
        "\n",
        "\n",
        "def gate_predict(model,X):\n",
        "    return np.round(model.predict(X))\n",
        "\n",
        "def tanh(x):\n",
        "    return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N_YOhM6F0Oi",
        "outputId": "74dd70df-c041-4412-cca3-b36a8f142c0b"
      },
      "source": [
        "X_train=np.array([[0., 0.],[0., 1.],[1., 0.],[1., 1.]])\n",
        "Y_train=np.array([0,1,1,0]) \n",
        "xor_gate=logical_gate(X_train,Y_train)\n",
        "gate_predict(xor_gate,X_train)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 14s 14s/step - loss: 0.5070 - accuracy: 0.5000\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4939 - accuracy: 0.5000\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4811 - accuracy: 0.5000\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4688 - accuracy: 0.5000\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4568 - accuracy: 0.5000\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4451 - accuracy: 0.5000\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4339 - accuracy: 0.5000\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.5000\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.5000\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.5000\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.5000\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3836 - accuracy: 0.5000\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.5000\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3669 - accuracy: 0.5000\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3590 - accuracy: 0.5000\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3514 - accuracy: 0.5000\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3441 - accuracy: 0.5000\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3369 - accuracy: 0.5000\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3301 - accuracy: 0.5000\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3237 - accuracy: 0.5000\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3176 - accuracy: 0.5000\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3118 - accuracy: 0.5000\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3062 - accuracy: 0.5000\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3007 - accuracy: 0.5000\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2953 - accuracy: 0.5000\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2900 - accuracy: 0.5000\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2850 - accuracy: 0.5000\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2801 - accuracy: 0.5000\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2754 - accuracy: 0.5000\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2708 - accuracy: 0.5000\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2663 - accuracy: 0.5000\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2619 - accuracy: 0.5000\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2577 - accuracy: 0.5000\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2536 - accuracy: 0.5000\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2496 - accuracy: 0.5000\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2456 - accuracy: 0.5000\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2423 - accuracy: 0.5000\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2391 - accuracy: 0.7500\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2359 - accuracy: 0.7500\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2328 - accuracy: 0.7500\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2298 - accuracy: 0.7500\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2268 - accuracy: 0.7500\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2239 - accuracy: 0.7500\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2210 - accuracy: 0.7500\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2181 - accuracy: 0.7500\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2153 - accuracy: 0.7500\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2126 - accuracy: 0.7500\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2099 - accuracy: 0.7500\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2072 - accuracy: 0.7500\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2047 - accuracy: 0.7500\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2025 - accuracy: 0.7500\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2004 - accuracy: 0.7500\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1982 - accuracy: 0.7500\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1961 - accuracy: 0.7500\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1939 - accuracy: 0.7500\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1918 - accuracy: 0.7500\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1897 - accuracy: 0.7500\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1876 - accuracy: 0.7500\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1855 - accuracy: 0.7500\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1834 - accuracy: 0.7500\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1814 - accuracy: 0.7500\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1793 - accuracy: 0.7500\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1773 - accuracy: 0.7500\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1755 - accuracy: 0.7500\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1736 - accuracy: 0.7500\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1717 - accuracy: 0.7500\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1698 - accuracy: 0.7500\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1680 - accuracy: 0.7500\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1661 - accuracy: 0.7500\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1643 - accuracy: 0.7500\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1625 - accuracy: 0.7500\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1608 - accuracy: 0.7500\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1590 - accuracy: 0.7500\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1573 - accuracy: 0.7500\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1556 - accuracy: 0.7500\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1539 - accuracy: 0.7500\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1524 - accuracy: 0.7500\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1508 - accuracy: 0.7500\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1493 - accuracy: 0.7500\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1477 - accuracy: 0.7500\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1462 - accuracy: 0.7500\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1447 - accuracy: 0.7500\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1432 - accuracy: 0.7500\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1417 - accuracy: 0.7500\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1402 - accuracy: 0.7500\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1388 - accuracy: 0.7500\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1373 - accuracy: 0.7500\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1359 - accuracy: 0.7500\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1345 - accuracy: 0.7500\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1330 - accuracy: 0.7500\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1316 - accuracy: 0.7500\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1302 - accuracy: 0.7500\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1288 - accuracy: 0.7500\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1275 - accuracy: 0.7500\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1261 - accuracy: 0.7500\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1248 - accuracy: 0.7500\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1234 - accuracy: 0.7500\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1221 - accuracy: 0.7500\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1208 - accuracy: 0.7500\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1195 - accuracy: 0.7500\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1183 - accuracy: 0.7500\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1171 - accuracy: 0.7500\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1159 - accuracy: 0.7500\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1148 - accuracy: 0.7500\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1136 - accuracy: 0.7500\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1124 - accuracy: 0.7500\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1113 - accuracy: 0.7500\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1101 - accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1090 - accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1079 - accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1068 - accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1057 - accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1046 - accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1036 - accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.1025 - accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1014 - accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1004 - accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0994 - accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0984 - accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0975 - accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0965 - accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0956 - accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0947 - accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0938 - accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0929 - accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0920 - accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0911 - accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0902 - accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0894 - accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0885 - accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0876 - accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0868 - accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0860 - accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0852 - accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0844 - accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0835 - accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0827 - accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0820 - accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0812 - accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0805 - accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0797 - accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0789 - accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0781 - accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0773 - accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0766 - accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0759 - accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0751 - accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0744 - accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0737 - accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0730 - accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0722 - accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0700 - accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0693 - accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0686 - accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0678 - accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0671 - accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0664 - accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0657 - accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0649 - accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0642 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0635 - accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0628 - accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0620 - accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0613 - accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0606 - accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0598 - accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0591 - accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0584 - accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0577 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0571 - accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0566 - accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0560 - accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0554 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0548 - accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0542 - accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0536 - accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0530 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0524 - accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0518 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0512 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0506 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0500 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0494 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0489 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0483 - accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0477 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0472 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0466 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0461 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0456 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0450 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0445 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0440 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0435 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0430 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0425 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0419 - accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0414 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxxeWQd4F0Ol",
        "outputId": "25f78b3a-8e73-4d52-c2ef-f331765c85aa"
      },
      "source": [
        "xor_gate.predict(X_train)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.18024263],\n",
              "       [0.7964949 ],\n",
              "       [0.7112078 ],\n",
              "       [0.08069269]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWW_P6ymF0Om",
        "outputId": "8b603393-d107-4b07-cc68-5dbab1dc1edf"
      },
      "source": [
        "X_train=np.array([[0., 0.],[0., 1.],[1., 0.],[1., 1.]])\n",
        "Y_train=np.array([0,0,0,1])\n",
        "\n",
        "and_gate=logical_gate(X_train,Y_train)\n",
        "gate_predict(and_gate,X_train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 0.2269 - accuracy: 0.5000\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2236 - accuracy: 0.5000\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2203 - accuracy: 0.5000\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2170 - accuracy: 0.5000\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2138 - accuracy: 0.5000\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2106 - accuracy: 0.5000\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2074 - accuracy: 0.5000\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2043 - accuracy: 0.5000\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2012 - accuracy: 0.5000\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1982 - accuracy: 0.5000\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1952 - accuracy: 0.7500\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1923 - accuracy: 0.7500\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1893 - accuracy: 0.7500\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1865 - accuracy: 0.7500\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1837 - accuracy: 0.7500\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1809 - accuracy: 0.7500\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1781 - accuracy: 0.7500\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1756 - accuracy: 0.7500\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1731 - accuracy: 0.7500\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1706 - accuracy: 0.7500\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1682 - accuracy: 0.7500\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1658 - accuracy: 0.7500\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1634 - accuracy: 0.7500\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1611 - accuracy: 0.7500\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1588 - accuracy: 0.7500\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1565 - accuracy: 0.7500\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1543 - accuracy: 0.7500\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1521 - accuracy: 0.7500\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1499 - accuracy: 0.7500\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1478 - accuracy: 0.7500\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1457 - accuracy: 0.7500\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1436 - accuracy: 0.7500\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1416 - accuracy: 0.7500\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1398 - accuracy: 0.7500\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1381 - accuracy: 0.7500\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1364 - accuracy: 0.7500\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1347 - accuracy: 0.7500\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1330 - accuracy: 0.7500\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1313 - accuracy: 0.7500\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1297 - accuracy: 0.7500\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1281 - accuracy: 0.7500\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1265 - accuracy: 0.7500\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1250 - accuracy: 0.7500\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1236 - accuracy: 0.7500\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1223 - accuracy: 0.7500\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1212 - accuracy: 0.7500\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1200 - accuracy: 0.7500\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1188 - accuracy: 0.7500\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1176 - accuracy: 0.7500\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1164 - accuracy: 0.7500\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1152 - accuracy: 0.7500\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1141 - accuracy: 0.7500\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1129 - accuracy: 1.0000\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1118 - accuracy: 1.0000\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1106 - accuracy: 1.0000\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1095 - accuracy: 1.0000\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1084 - accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1072 - accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1061 - accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1050 - accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1039 - accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1028 - accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1006 - accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0995 - accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0984 - accuracy: 1.0000\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0974 - accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0963 - accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0953 - accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0942 - accuracy: 1.0000\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0932 - accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0922 - accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0912 - accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0903 - accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0893 - accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0883 - accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0874 - accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0864 - accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0855 - accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0845 - accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0836 - accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0827 - accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0818 - accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0809 - accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0800 - accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0792 - accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0783 - accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0774 - accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0765 - accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0756 - accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0747 - accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0739 - accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0730 - accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0721 - accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0713 - accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0696 - accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0687 - accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0678 - accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0670 - accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0661 - accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0645 - accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0612 - accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0604 - accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0596 - accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0588 - accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0580 - accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0573 - accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0565 - accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0557 - accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0550 - accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0542 - accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0535 - accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0528 - accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0520 - accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0513 - accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0506 - accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0499 - accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0492 - accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0485 - accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0478 - accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0470 - accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0464 - accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0457 - accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0451 - accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0444 - accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0437 - accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0431 - accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0424 - accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0418 - accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0405 - accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0399 - accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0393 - accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0387 - accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0380 - accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0374 - accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0368 - accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0362 - accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0356 - accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0350 - accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0344 - accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0339 - accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0333 - accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0327 - accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0322 - accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0316 - accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0311 - accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0305 - accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0300 - accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0295 - accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0290 - accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0285 - accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0280 - accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0275 - accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0270 - accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.0260 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0256 - accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0251 - accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0247 - accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0242 - accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0238 - accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0234 - accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0229 - accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0225 - accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0221 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0217 - accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0214 - accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0210 - accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0206 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0198 - accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0195 - accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0188 - accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0184 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0181 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0178 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0174 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0171 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0168 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0165 - accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0162 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0159 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0156 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0153 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0148 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0146 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0143 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0140 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0138 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0135 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0133 - accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0131 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.],\n",
              "       [ 0.],\n",
              "       [ 0.],\n",
              "       [ 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UiNUMCaF0Om"
      },
      "source": [
        "## save model & load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb77Hrg0F0On"
      },
      "source": [
        "from keras.models import load_model\n",
        "# creates a HDF5 file\n",
        "xor_gate.save('xor_gate.h5')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0gWu87pF0Oo",
        "outputId": "bced6a62-2c04-4c72-9f80-b8e352bcd290"
      },
      "source": [
        "#load model\n",
        "xor_gate=load_model ('xor_gate.h5')\n",
        "x=np.array([1,1]).reshape(1,2)\n",
        "print(gate_predict(xor_gate,x))\n",
        "print(gate_predict_prob(xor_gate,x))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.]]\n",
            "[[0.08069263]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4noGH5VfF0Op",
        "outputId": "a9422956-ee24-43e3-f878-84b5463ae179"
      },
      "source": [
        "xor_gate.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "layer1 (Dense)               (None, 8)                 24        \n",
            "_________________________________________________________________\n",
            "layer2 (Dense)               (None, 16)                144       \n",
            "_________________________________________________________________\n",
            "layer3 (Dense)               (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 185\n",
            "Trainable params: 185\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgSZx_CcF0Op",
        "outputId": "2769875c-519d-4e9e-83c9-73190dc4c43d"
      },
      "source": [
        "layer_names=[layer.name for layer in xor_gate.layers]\n",
        "layer_names"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['layer1', 'layer2', 'layer3']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzNg8GO9F0Oq",
        "outputId": "1149da56-d61b-4491-eaa8-a9fa5954bece"
      },
      "source": [
        "import h5py\n",
        "\n",
        "# \n",
        "MODEL_PATH = 'xor_gate.h5'\n",
        "\n",
        "# \n",
        "print(\"...\")\n",
        "with h5py.File(MODEL_PATH, 'r') as f:\n",
        "    dense_1 = f['/model_weights/layer1/layer1']\n",
        "    dense_1_bias =  dense_1['bias:0'][:]\n",
        "    dense_1_kernel = dense_1['kernel:0'][:]\n",
        "\n",
        "    dense_2 = f['/model_weights/layer2/layer2']\n",
        "    dense_2_bias = dense_2['bias:0'][:]\n",
        "    dense_2_kernel = dense_2['kernel:0'][:]\n",
        "\n",
        "    dense_3 = f['/model_weights/layer3/layer3']\n",
        "    dense_3_bias = dense_3['bias:0'][:]\n",
        "    dense_3_kernel = dense_3['kernel:0'][:]\n",
        "\n",
        "print(\"weight\\n%s\\n\"%dense_1_kernel)\n",
        "print(\"bias\\n%s\\n\"%dense_1_bias)\n",
        "print(\"weight\\n%s\\n\"%dense_2_kernel)\n",
        "print(\"bias\\n%s\\n\"%dense_2_bias)\n",
        "print(\"weight\\n%s\\n\"%dense_3_kernel)\n",
        "print(\"bias\\n%s\\n\"%dense_3_bias)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "...\n",
            "weight\n",
            "[[ 0.24905501 -0.339099   -0.12128493 -0.42329693 -0.70107776 -0.67215127\n",
            "   0.63423157 -0.23021457]\n",
            " [ 0.16203013 -0.21602756  0.79687893 -0.3137589   0.23085931  0.66411394\n",
            "  -0.00731821  0.83181304]]\n",
            "\n",
            "bias\n",
            "[ 0.00306694  0.          0.06789368  0.         -0.0154349   0.00773847\n",
            "  0.08891645  0.15645568]\n",
            "\n",
            "weight\n",
            "[[-0.38696623 -0.12253991  0.0934083   0.12008546 -0.00566578  0.40662643\n",
            "   0.47881636  0.37053555  0.39380884 -0.03174127 -0.01976946 -0.177175\n",
            "   0.4709144   0.32313803 -0.25729766  0.43209478]\n",
            " [ 0.06520236  0.47239304 -0.21638238 -0.23086226  0.02741468 -0.46196914\n",
            "  -0.26876318 -0.19474137  0.3693912  -0.29719603 -0.4176445   0.3814255\n",
            "  -0.3785485  -0.32519352 -0.40759957 -0.11734462]\n",
            " [-0.06501132  0.17263384 -0.23867549 -0.21026795 -0.46341693 -0.18885984\n",
            "  -0.38282272  0.12471607  0.2865164  -0.47667062  0.15295742  0.516979\n",
            "  -0.2816005  -0.36028752  0.3374961  -0.14877528]\n",
            " [-0.04141843  0.36702788 -0.00165403 -0.2415868  -0.14948237  0.4016894\n",
            "  -0.19702446 -0.4971658  -0.35612297  0.08094621  0.46426427  0.14572537\n",
            "  -0.29870963 -0.3508469   0.2841841   0.03473341]\n",
            " [-0.43913364 -0.22094682 -0.48572832 -0.30496895  0.1509459  -0.00901699\n",
            "  -0.12477358 -0.21521226 -0.3419317  -0.0816952   0.41986686  0.09753615\n",
            "  -0.30470753  0.28776038  0.35837007  0.2081835 ]\n",
            " [-0.29509467 -0.46791482  0.07346679 -0.43022373  0.3482045  -0.03527738\n",
            "   0.44978642  0.31194955 -0.52917033 -0.20903885  0.31963238 -0.37630996\n",
            "  -0.16167374  0.37678277  0.23794377 -0.3770614 ]\n",
            " [-0.21224165  0.13850594 -0.1352047   0.34679878 -0.41988766  0.39707965\n",
            "   0.6428183   0.4572321  -0.07978106  0.1722743  -0.5025887  -0.60271966\n",
            "   0.18950765 -0.36225307 -0.3123939   0.21281223]\n",
            " [ 0.36987397  0.43606892  0.28446677 -0.27095252 -0.1558572  -0.4762612\n",
            "   0.09398711  0.5182567   0.16597453  0.2798767  -0.40511674  0.16231786\n",
            "  -0.71242964  0.03144176  0.1106103   0.33123544]]\n",
            "\n",
            "bias\n",
            "[ 0.06485591 -0.06923048 -0.02597127  0.06128724  0.          0.05067302\n",
            "  0.06357995  0.06766583 -0.04178482 -0.11969815 -0.03891987 -0.00356347\n",
            "  0.10861909 -0.05806602 -0.00653381 -0.07926469]\n",
            "\n",
            "weight\n",
            "[[-0.3503958 ]\n",
            " [-0.5093781 ]\n",
            " [-0.22385105]\n",
            " [ 0.63986164]\n",
            " [ 0.00177962]\n",
            " [ 0.245799  ]\n",
            " [ 0.1234737 ]\n",
            " [ 0.6010383 ]\n",
            " [-0.7579805 ]\n",
            " [-0.32171166]\n",
            " [-0.48702356]\n",
            " [ 0.6144213 ]\n",
            " [ 0.5128231 ]\n",
            " [-0.43552402]\n",
            " [ 0.5589431 ]\n",
            " [-0.35902274]]\n",
            "\n",
            "bias\n",
            "[0.06568503]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltDS4QH_F0Or"
      },
      "source": [
        "def relu(x):\n",
        "    return np.maximum(0, x)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UraSmJ6_F0Os",
        "outputId": "e7bc7638-1c69-4ea1-d40c-37a0178c8746"
      },
      "source": [
        "\n",
        "x=np.array([1,1])\n",
        "print('name:',xor_gate.layers[0].name)\n",
        "weights, biases = xor_gate.layers[0].get_weights()\n",
        "x=np.dot(x,weights)+biases\n",
        "x=relu(x)\n",
        "print('name:',xor_gate.layers[1].name)\n",
        "weights, biases = xor_gate.layers[1].get_weights()\n",
        "x=np.dot(x,weights)+biases\n",
        "x=relu(x)\n",
        "print('name:',xor_gate.layers[2].name)\n",
        "weights, biases = xor_gate.layers[2].get_weights()\n",
        "x=np.dot(x,weights)+biases\n",
        "x=tanh(x)\n",
        "print('x:',x)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name: layer1\n",
            "name: layer2\n",
            "name: layer3\n",
            "x: [0.08069262]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt8ZXoNEF_vz"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}